{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BIOS_534_Regression.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFcu3b96yx7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z5r-GiXy2X4",
        "colab_type": "text"
      },
      "source": [
        "# BIOS 534 - Regression\n",
        "\n",
        "This note book provides a basic equivalent to the R code presented in class on 3/26. This is not intended to be a one-to-one, lock step reproduction of the R code because, of necessity, the code flow will be different because Python is a different language with its own way of doing things. So it's not possible to make things look the same between the two languages nor should one even try. Each has its strengths. The larger point(s) of the notebook is to show the following:\n",
        "\n",
        "*   How to Build A Regression Model And Compute RMSE\n",
        "*   How To Do K Fold Validation Using a Helper Function\n",
        "*   How To Do K Fold Validation Manually\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2gfAty-0zvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import some needed modules\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqtMYB_r-OnK",
        "colab_type": "text"
      },
      "source": [
        "# A Basic Example\n",
        "\n",
        "So we'll start by building a Regression model on the entire mtcars data frame. We did this with the R example. Ordinarily, you wouldn't do this but this gives you an idea of how you would build the model. We'll worry about train / test and cross validation later in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aAUm7J509xc",
        "colab_type": "text"
      },
      "source": [
        "## Read In The Data\n",
        "\n",
        "Next, we read in the mtcars data frame from the Internet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1UiBOos1KEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "534fd3cc-d14a-401b-8b7a-6807e2c3d379"
      },
      "source": [
        "# Read In The mtcars data frame\n",
        "url = \"https://raw.githubusercontent.com/steviep42/bios534_spring_2020/master/data/mtcars.csv\"\n",
        "dfmt = pd.read_csv(url) \n",
        "dfmt.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32 entries, 0 to 31\n",
            "Data columns (total 11 columns):\n",
            "mpg     32 non-null float64\n",
            "cyl     32 non-null int64\n",
            "disp    32 non-null float64\n",
            "hp      32 non-null int64\n",
            "drat    32 non-null float64\n",
            "wt      32 non-null float64\n",
            "qsec    32 non-null float64\n",
            "vs      32 non-null int64\n",
            "am      32 non-null int64\n",
            "gear    32 non-null int64\n",
            "carb    32 non-null int64\n",
            "dtypes: float64(5), int64(6)\n",
            "memory usage: 2.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM47egfX1lQ5",
        "colab_type": "text"
      },
      "source": [
        "## Identify The Target Feature\n",
        "\n",
        "So we need to determine what the target / outcome feature is and what the predictor features are. We want to predict mpg as a function of weight so we need to index into the data frame to get those values.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toxznIik2GfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "ee072705-03ac-4cd2-8264-0258cbe95a3c"
      },
      "source": [
        "# Identify the Y / outcome feature\n",
        "Y = dfmt.mpg\n",
        "\n",
        "# Identify the predictor features. Since we are using just a single column \n",
        "# we have to reshape it. Don't know why but that's the way it is\n",
        "\n",
        "X = np.ravel(dfmt.wt).reshape(-1,1)\n",
        "\n",
        "# Print them Out\n",
        "Y\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     21.0\n",
              "1     21.0\n",
              "2     22.8\n",
              "3     21.4\n",
              "4     18.7\n",
              "5     18.1\n",
              "6     14.3\n",
              "7     24.4\n",
              "8     22.8\n",
              "9     19.2\n",
              "10    17.8\n",
              "11    16.4\n",
              "12    17.3\n",
              "13    15.2\n",
              "14    10.4\n",
              "15    10.4\n",
              "16    14.7\n",
              "17    32.4\n",
              "18    30.4\n",
              "19    33.9\n",
              "20    21.5\n",
              "21    15.5\n",
              "22    15.2\n",
              "23    13.3\n",
              "24    19.2\n",
              "25    27.3\n",
              "26    26.0\n",
              "27    30.4\n",
              "28    15.8\n",
              "29    19.7\n",
              "30    15.0\n",
              "31    21.4\n",
              "Name: mpg, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TsUsVCI4i5k",
        "colab_type": "text"
      },
      "source": [
        "## Create The Linear Regression Object\n",
        "\n",
        "Now we will create a Linear Regression object and start working with that. We'll first build the model using the entire data set itself. Ordinarily, this isn't something that you would do but this is just a first example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4UctkQG4ckz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a723fcdb-4e63-4f87-fc16-1aef278f2d70"
      },
      "source": [
        "# Initialize a Linear Regression object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model with the training data\n",
        "model.fit(X,Y)\n",
        "\n",
        "# Get the coefficeints of the trained model\n",
        "print('\\nCoefficient of model :', model.coef_)\n",
        "\n",
        "# Get the intercept\n",
        "print('slope:', model.intercept_)\n",
        "\n",
        "# R-squared\n",
        "r_sq = model.score(X, Y)\n",
        "print('R-Squared:', r_sq.round(3))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Coefficient of model : [-5.34447157]\n",
            "slope: 37.28512616734204\n",
            "R-Squared: 0.753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC1eQis95cbE",
        "colab_type": "text"
      },
      "source": [
        "## Making Some Predictions\n",
        "\n",
        "Look at the predictions using the training data. We are using the same dataset that we trained the model on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL61tSj45pcz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "053e24e4-ed51-44bf-8367-bc2da8757987"
      },
      "source": [
        "predict_train = model.predict(X)\n",
        "print('\\nMPG on training data',predict_train) \n",
        "\n",
        "# Root Mean Squared Error on training dataset\n",
        "rmse_train = mean_squared_error(Y,predict_train)**(0.5)\n",
        "print('\\nRMSE on training dataset : ', rmse_train.round(2))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MPG on training data [23.28261065 21.9197704  24.88595212 20.10265006 18.90014396 18.79325453\n",
            " 18.20536265 20.23626185 20.45004071 18.90014396 18.90014396 15.53312687\n",
            " 17.3502472  17.08302362  9.22665041  8.29671236  8.71892561 25.52728871\n",
            " 28.65380458 27.47802083 24.11100374 18.47258623 18.92686632 16.76235533\n",
            " 16.73563297 26.94357367 25.847957   29.19894068 20.34315128 22.48093991\n",
            " 18.20536265 22.4274952 ]\n",
            "\n",
            "RMSE on training dataset :  2.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvnDTKBv6Ds_",
        "colab_type": "text"
      },
      "source": [
        "# Use a Training / Test Pair\n",
        "\n",
        "So as we learned in the lecture, a reasonable next step is to create a Train / Test pair which would help provide a better estiamte of out-of-sample error than training purely on the data set. Just as R has some helper functions for this, so does Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK2bMG636lA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09b67068-5ec6-4663-876a-4697aa2b5877"
      },
      "source": [
        "# Import the train / test module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# We'll use an 80/20 split\n",
        "seed = 7\n",
        "test_size = .20\n",
        "\n",
        "# The train_test_split function does the work\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "\n",
        "# Check the sizes of the Train Data\n",
        "X_train.size\n",
        "Y_train.size\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFOCXZuJ6_Xf",
        "colab_type": "text"
      },
      "source": [
        "## Repeat The Regression\n",
        "\n",
        "So we'll do the same as before except this time we'll train the model using only the training subset. Then we'll see what the RMSE is on the training data. After that we'll then use it on the test data to see if the RMSE on the test data is similar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqPdG-Gb7aL2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "a5e63db1-d300-49be-966d-878eb2e347d6"
      },
      "source": [
        "# Initialize another Linear Regression object\n",
        "model2 = LinearRegression()\n",
        "\n",
        "# Fit the model with the training data\n",
        "model2.fit(X_train,Y_train)\n",
        "\n",
        "# Look at the predictions using the train data\n",
        "predict_train = model2.predict(X_train)\n",
        "print('\\nMPG on training data',predict_train) \n",
        "\n",
        "# Root Mean Squared Error on training dataset\n",
        "rmse_train = mean_squared_error(Y_train,predict_train)**(0.5)\n",
        "print('\\nRMSE on train dataset : ', rmse_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MPG on training data [ 8.76098762 29.74213411 25.98063942 18.75331338 15.74192754 22.80499616\n",
            " 17.60351151 29.18365891 23.68103568 18.47955103 18.47955103 16.97385811\n",
            " 20.66964983 19.19133314 22.85974863 20.77915477  9.28113608 20.56014489\n",
            " 17.00123435 27.97910457 20.42326372 19.21870938 27.43157987 19.19133314\n",
            "  8.3284431 ]\n",
            "\n",
            "RMSE on train dataset :  3.2206761356209834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VLRIOUe9ZRX",
        "colab_type": "text"
      },
      "source": [
        "## RMSE On The Test Data\n",
        "\n",
        "So now let's look at the performance on the test data set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJkco4EY9diI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "501ae3fb-bb4e-4264-d386-58d7a86db18a"
      },
      "source": [
        "# Predict the target feature using the testing dataset\n",
        "predict_test = model2.predict(X_test)\n",
        "print('\\nMPG on test data',predict_test) \n",
        "\n",
        "# Now compute the Root Mean Squared Error on the test dataset\n",
        "rmse_test = mean_squared_error(Y_test,predict_test)**(0.5)\n",
        "print('\\nRMSE on test dataset : ', rmse_test)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MPG on test data [25.32360978 26.30915424 22.2848477  19.19133314 17.32974916 19.0818282\n",
            " 24.52969897]\n",
            "\n",
            "RMSE on test dataset :  1.8045175586043039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTtVCiui_9UQ",
        "colab_type": "text"
      },
      "source": [
        "# Assisted Cross Fold Validation\n",
        "\n",
        "We'll use a convenient function from the sklearn library called cross_validate to help us. This is somewhat similar to the train function from the R caret package in that it automates the creation of a series of train / test data splits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rb2yIEgAMpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the helper function\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "# Create a Kfold object - K=4 folds\n",
        "kfold = KFold(n_splits=4, random_state=7, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEOEz4MiFJBP",
        "colab_type": "text"
      },
      "source": [
        "## The Kold Function\n",
        "\n",
        "The KFold function will manage the creation of the folds, in this case 4 of them.  We get back the indices corresponding to rows of the training data. We also get back the indices corresponding to the holdout or test fold "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxtGK2jFFOiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "d0175a3c-1444-46b0-c142-ee51982ea00d"
      },
      "source": [
        "for train_index, test_index in kfold.split(X,Y):\n",
        "      print(train_index)\n",
        "      print(test_index,\"\\n\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  3  4  6  7  8 10 11 12 14 15 17 18 19 21 22 23 24 25 27 28 29 30 31]\n",
            "[ 1  2  5  9 13 16 20 26] \n",
            "\n",
            "[ 1  2  3  4  5  6  7  8  9 10 13 14 15 16 19 20 22 23 24 25 26 28 29 30]\n",
            "[ 0 11 12 17 18 21 27 31] \n",
            "\n",
            "[ 0  1  2  3  4  5  7  9 11 12 13 15 16 17 18 19 20 21 22 23 25 26 27 31]\n",
            "[ 6  8 10 14 24 28 29 30] \n",
            "\n",
            "[ 0  1  2  5  6  8  9 10 11 12 13 14 16 17 18 20 21 24 26 27 28 29 30 31]\n",
            "[ 3  4  7 15 19 22 23 25] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fun5TsHXFsyx",
        "colab_type": "text"
      },
      "source": [
        "## The cross_valdiate function\n",
        "\n",
        "Next up we will initialize the model and use the cross_validate function to manage the creation of 4 models, one for each fold, and then get a sense of the RMSE for each of the four models. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pueXIvxnGBqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "13c20c18-4029-4a0a-de4a-abc238ea349c"
      },
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Create a Linear Regression Object\n",
        "model3 = LinearRegression()\n",
        "\n",
        "# We have to designate a scoring metric \n",
        "mse = make_scorer(mean_squared_error)\n",
        "\n",
        "# The cross_validate function handles the execution of the model\n",
        "cv  = cross_validate(model3,X_train,Y_train,scoring=(mse), cv=kfold)\n",
        "\n",
        "# Here we print out the rmse of the test / holdout data\n",
        "print((cv['test_score']**0.5))\n",
        "\n",
        "# Look at the mean of this RMSE array\n",
        "print((cv['test_score']**0.5).mean().round(2))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.49296896 4.05455881 3.55885475 3.64312596]\n",
            "3.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVfiogY2HbeT",
        "colab_type": "text"
      },
      "source": [
        "# Manual Cross Fold Validation \n",
        "\n",
        "The following is what you might do if you wanted to do the cross fold valdiation on your own without using the convenience of the cross_validate function. This is useful if you want finer grained control over the individual per fold models and perhaps wanted to make predictions on the hold out fold as part of the loop.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYAuon1hPaCk",
        "colab_type": "text"
      },
      "source": [
        "## Loop Through The Folds\n",
        "\n",
        "Here we can create a loop that processes each of the folds. Just to summarize, here is what this process is doing. In reality, this is the same process as in the most recent section just that here we are writing our own loop\n",
        "\n",
        "1.   We split up the training set into K folds (4 here)\n",
        "2.   A Model is trained usinf K-1 folds as Training Data\n",
        "3.   The remaining fold is used as a test data set\n",
        "4.   Make a prediction on the test data and compute the RMSE\n",
        "5.   Steps 2 -4 are repeated until all folds have been used as test data \n",
        "6.   At the end, return the vector containing all compute RMSEs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLQZ8HO9RxfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5d5e7be1-b744-4201-a998-46e9303c677b"
      },
      "source": [
        "# Set up some vectors to collect info\n",
        "\n",
        "rmse_train_info = np.empty(0)\n",
        "rmse_test_info = np.empty(0)\n",
        "ii = 1\n",
        "\n",
        "# Main processing loop for the folds\n",
        "\n",
        "for train_index, test_index in kfold.split(X, Y):\n",
        "  # split data coming from each of the 4 folds\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "        \n",
        "        # Initialize a model\n",
        "        regress = LinearRegression()\n",
        "        \n",
        "        # Fit the Model\n",
        "        regress.fit(X_train,Y_train)\n",
        "        \n",
        "        # Predict the target on the training dataset\n",
        "        predict_train = regress.predict(X_train)\n",
        "  \n",
        "        # Root Mean Squared Error on training dataset\n",
        "        rmse_train = mean_squared_error(Y_train,predict_train)**(0.5)\n",
        "        print(\"Training RMSE for loop\",ii,\"is:\", rmse_train)\n",
        "       \n",
        "        # Append the rmse to the rmse_train_info vector\n",
        "        rmse_train_info = np.append(rmse_train_info,rmse_train)\n",
        "        \n",
        "        # Now let's do a prediction on the test data\n",
        "        predict_test = regress.predict(X_test)\n",
        "        \n",
        "        # Root Mean Squared Error on training dataset\n",
        "        rmse_test = mean_squared_error(Y_test,predict_test)**(0.5)\n",
        "        print(\"Test RMSE for loop\",ii,\"is:\", rmse_test,\"\\n\")\n",
        "       \n",
        "        # Append the rmse to the rmse_test_info vector\n",
        "        rmse_test_info = np.append(rmse_test_info,rmse_test)\n",
        "\n",
        "        ii = ii+1\n",
        "        "
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training RMSE for loop 1 is: 2.9952712670326016\n",
            "Test RMSE for loop 1 is: 3.1200477195304077 \n",
            "\n",
            "Training RMSE for loop 2 is: 2.91766901106953\n",
            "Test RMSE for loop 2 is: 3.2438734462358703 \n",
            "\n",
            "Training RMSE for loop 3 is: 2.932394228015021\n",
            "Test RMSE for loop 3 is: 3.1009277330714276 \n",
            "\n",
            "Training RMSE for loop 4 is: 2.759487962556093\n",
            "Test RMSE for loop 4 is: 3.5729602245510548 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXBvP75XTlaO",
        "colab_type": "text"
      },
      "source": [
        "## Compare the RMSE Outcomes\n",
        "\n",
        "As part of the loop we captured the RMSE values for the the training and test folds. We can look at the vectors and compute some basic statistics on them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3f9VSZhT6kf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "aeb938bd-3c06-414f-95ce-51c8e67aa2ee"
      },
      "source": [
        "print(\"RMSE For Training Folds\", rmse_train_info)\n",
        "\n",
        "print(\"RMSE For Test Folds\",rmse_test_info)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE For Training Folds [2.99527127 2.91766901 2.93239423 2.75948796]\n",
            "RMSE For Test Folds [3.12004772 3.24387345 3.10092773 3.57296022]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD3o-9zOUeHG",
        "colab_type": "text"
      },
      "source": [
        "Next what is the mean of these vectors:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCV2wPRNUhF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6b1df93e-5099-4037-888c-cbb88f9b1a9f"
      },
      "source": [
        "print(\"RMSE Training mean:\",rmse_train_info.mean())\n",
        "print(\"RMSE Test mean:\",rmse_test_info.mean())\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE Training mean: 2.9012056171683116\n",
            "RMSE Test mean: 3.2594522808471904\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}